实战环境搭建

1. JDK安装                  5. Zookeeper安装

2. Scala安装                6. HBase安装

3. Maven安装                7. Spark安装

4. Hadoop安装               8. IDEA+Maven+Spark Streaming








1~3 比较简单  自行看官网安装配置环境变量即可


4. Hadoop安装 (详细请到Spark SQL的笔记上去看)
下载、解压
配置系统环境变量、检查是否安装成功
配置文件修改


5. HBase的安装
    下载、解压

    配置: 1. $HBASE_HOME/conf/hbase.env.sh
     	     export JAVA_HOME=/home/xingtb/app/jdk1.8.0_181

     	     # Tell HBase whether it should manage it's own instance of Zookeeper or not. (是否使用HBase自带的Zookeeper)
             # export HBASE_MANAGES_ZK=true
             export HBASE_MANAGES_ZK=false

          2. $HBASE_HOME/conf/hbase-site.xml
             <property>
                 <name>hbase.rootdir</name>
                 <value>hdfs://hadoop001:8020/hbase</value>
             </property>
             <property>
                 <name>hbase.cluster.distributed</name>
                 <value>true</value>
             </property>
             <property>
                 <name>hbase.zookeeper.quorum</name>
                 <value>hadoop001:2181</value>
             </property>

           3. $HBASE_HOME/conf/regionservers
              hadoop001




